_BASE_: "robot_config.yaml"

policy:
  init_noise_std: 1.0
  actor_class: "SimpleMLP"
  critic_class: "SimpleMLP"
  actor_hidden_dims: [512, 256, 128]
  critic_hidden_dims: [768, 256, 128]

algorithm:
  entropy_coef: 0.001
  learning_rate: 0.00001
  num_learning_epochs: 2
  gamma: 0.994
  lam: 0.9
  num_mini_batches: 4

runner:
  num_steps_per_env: 60
  max_iterations: 3001

  # deque
  max_actor_history: 5
  max_critic_history: 3

  # logging
  save_interval: 100
  experiment_name: 'HIT_Imitate_ppo'
  run_name: '0.1'
